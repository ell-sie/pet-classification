{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22170 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where you saved your dataset\n",
    "data_dir = r\"C:\\Users\\Lenovo\\Downloads\\oxford-iiit-pet\"\n",
    "# Create a dataset\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all file paths\n",
    "all_file_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir)]\n",
    "\n",
    "# Assume that the label for each image is contained in the file name\n",
    "# For example, if the file name is 'cat_001.jpg', the label is 'cat'\n",
    "all_labels = [os.path.splitext(os.path.basename(fname))[0].split('_')[0] for fname in all_file_paths]\n",
    "\n",
    "# Create a mapping of class names to integers\n",
    "class_names = np.unique(all_labels)\n",
    "class_to_index = {name: index for index, name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can split this data into training and validation sets\n",
    "train_file_paths = all_file_paths[:16000]\n",
    "train_labels = [class_to_index[label] for label in all_labels[:16000]]\n",
    "\n",
    "val_file_paths = all_file_paths[16000:]\n",
    "val_labels = [class_to_index[label] for label in all_labels[16000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the custom data generator\n",
    "def load_and_preprocess_image(path):\n",
    "    try:\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [180, 180])\n",
    "        image /= 255.0  # normalize to [0,1] range\n",
    "    except:\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "def custom_data_generator(file_paths, labels, batch_size=32):\n",
    "    assert len(file_paths) == len(labels)\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_file_paths = file_paths[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        image_batch = []\n",
    "        label_batch = []\n",
    "        for fp, label in zip(batch_file_paths, batch_labels):\n",
    "            image = load_and_preprocess_image(fp)\n",
    "            if image is not None:\n",
    "                image_batch.append(image)\n",
    "                label_batch.append(label)\n",
    "        yield np.array(image_batch), np.array(label_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    custom_data_generator,\n",
    "    args=[train_file_paths, train_labels, 32],  # replace with your actual data\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = dataset.skip(16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple Model\n",
    "model1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Model\n",
    "model2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "An error occurred during training: Graph execution error:\n",
      "\n",
      "Detected at node PyFunc defined at (most recent call last):\n",
      "<stack traces unavailable>\n",
      "TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, 180, 180, 3) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (0,) where an element of shape (None, 180, 180, 3) was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_1504]\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "try:\n",
    "    history1 = model1.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "    history2 = model2.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m], loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper left\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 21\u001b[0m plot_history(\u001b[43mhistory1\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m plot_history(history2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history1' is not defined"
     ]
    }
   ],
   "source": [
    "# Now you can plot the training history\n",
    "def plot_history(history, title):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history1, 'Model 1')\n",
    "plot_history(history2, 'Model 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
