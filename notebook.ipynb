{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where you saved your dataset\n",
    "data_dir = r\"C:\\Users\\Lenovo\\Downloads\\oxford-iiit-pet\"\n",
    "# Create a dataset\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all file paths\n",
    "all_file_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir)]\n",
    "\n",
    "# Assume that the label for each image is contained in the file name\n",
    "# For example, if the file name is 'cat_001.jpg', the label is 'cat'\n",
    "all_labels = [os.path.splitext(os.path.basename(fname))[0].split('_')[0] for fname in all_file_paths]\n",
    "\n",
    "# Now you can split this data into training and validation sets\n",
    "train_file_paths = all_file_paths[:16000]\n",
    "train_labels = all_labels[:16000]\n",
    "\n",
    "val_file_paths = all_file_paths[16000:]\n",
    "val_labels = all_labels[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the custom data generator\n",
    "def load_and_preprocess_image(path):\n",
    "    try:\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [180, 180])\n",
    "        image /= 255.0  # normalize to [0,1] range\n",
    "    except:\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "def custom_data_generator(file_paths, labels):\n",
    "    assert len(file_paths) == len(labels)\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        image = load_and_preprocess_image(file_path)\n",
    "        if image is not None:\n",
    "            yield image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    custom_data_generator,\n",
    "    args=[train_file_paths, train_labels],  # replace with your actual data\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(180, 180, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = dataset.skip(16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Model\n",
    "model1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Model\n",
    "model2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "try:\n",
    "    history1 = model1.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "    history2 = model2.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can plot the training history\n",
    "def plot_history(history, title):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history1, 'Model 1')\n",
    "plot_history(history2, 'Model 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
